{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b28381e2",
   "metadata": {},
   "source": [
    "# Libraries & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac2db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kevin Nathanael\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, Tuple, List, Any, Optional\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b70451",
   "metadata": {},
   "source": [
    "# Data Classes Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AgentResult:\n",
    "    \"\"\"Holds the output from a single worker agent.\"\"\"\n",
    "    anomaly_detected: bool\n",
    "    score: float\n",
    "    reasons: List[str]  # Generated by the rules engine\n",
    "    summary: str        # Generated by the LLM\n",
    "\n",
    "@dataclass\n",
    "class SupervisorDecision:\n",
    "    \"\"\"Holds the final decision from the supervisor agent.\"\"\"\n",
    "    risk_level: str  # \"LOW\", \"MODERATE\", \"HIGH\"\n",
    "    global_score: float\n",
    "    recommendations: List[str]\n",
    "\n",
    "@dataclass\n",
    "class FinalReport:\n",
    "    \"\"\"Represents the entire structured output for a single row, matching the ground truth.\"\"\"\n",
    "    row_index: int\n",
    "    description: str\n",
    "    agent_outputs: Dict[str, AgentResult] # Using a Dict is key for easy lookup\n",
    "    supervisor_decision: SupervisorDecision\n",
    "\n",
    "@dataclass\n",
    "class EvaluationMetrics:\n",
    "    \"\"\"Holds all the metrics from comparing the FinalReport to the ground truth.\"\"\"\n",
    "    # Anomaly detection accuracy for all agents combined\n",
    "    anomaly_detection_accuracy: float\n",
    "    \n",
    "    # Accuracy of the supervisor's final risk level classification\n",
    "    risk_level_accuracy: float\n",
    "    \n",
    "    # Average semantic similarity of the agent's reasons\n",
    "    reason_similarity_score: float\n",
    "    \n",
    "    # Semantic similarity of the supervisor's recommendations\n",
    "    recommendation_similarity_score: float\n",
    "    \n",
    "    # The error margin of the calculated global score vs. expected\n",
    "    global_score_error: float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430dd567",
   "metadata": {},
   "source": [
    "# Agent & Supervisor Defininitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81590eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. It only defines what the LLM will return: a summary.\n",
    "class AgentLLMOutput(BaseModel):\n",
    "    \"\"\"Defines the expected JSON output structure from the worker agent's LLM call.\"\"\"\n",
    "    summary: str = Field(description=\"A brief, one-sentence summary of the detected anomalies.\")\n",
    "\n",
    "# 2. The new WorkerAgent class contains all the logic for rules, scoring, and summarization.\n",
    "class WorkerAgent:\n",
    "    \"\"\"A configurable worker agent that performs analysis based on rules and scoring logic.\"\"\"\n",
    "\n",
    "    def __init__(self, agent_name: str, config: Dict, llm: ChatOpenAI):\n",
    "        self.name = agent_name\n",
    "        self.features = config['features']\n",
    "        self.rules = config['rules']\n",
    "        self.scoring_config = config['scoring']\n",
    "        self.llm = llm\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(config['prompt'])\n",
    "        self.parser = JsonOutputParser(pydantic_object=AgentLLMOutput)\n",
    "\n",
    "    def _apply_rules(self, data_input: Dict) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"Applies the deterministic rules from the config to detect anomalies.\"\"\"\n",
    "        anomalies_found = False\n",
    "        reasons = []\n",
    "        for rule in self.rules:\n",
    "            feature = rule['feature']\n",
    "            value = data_input.get(feature)\n",
    "            if value is None:\n",
    "                continue\n",
    "\n",
    "            threshold = rule['threshold']\n",
    "            triggered = False\n",
    "            if rule['condition'] == 'greater_than' and value > threshold:\n",
    "                triggered = True\n",
    "            elif rule['condition'] == 'less_than' and value < threshold:\n",
    "                triggered = True\n",
    "            elif rule['condition'] == 'outside_range' and (value < threshold[0] or value > threshold[1]):\n",
    "                triggered = True\n",
    "            elif rule['condition'] == 'equals' and value == threshold:\n",
    "                triggered = True\n",
    "\n",
    "            if triggered:\n",
    "                anomalies_found = True\n",
    "                reasons.append(rule['reason'].format(value=value, threshold=threshold))\n",
    "        return anomalies_found, reasons\n",
    "\n",
    "    def _calculate_score(self, data_input: Dict) -> float:\n",
    "        \"\"\"Calculates a 0-1 risk score based on the scoring configuration.\"\"\"\n",
    "        scores = [0.0] # Start with 0.0 to handle cases with no matching features\n",
    "        for config_item in self.scoring_config:\n",
    "            feature = config_item['feature']\n",
    "            value = data_input.get(feature)\n",
    "            if value is None:\n",
    "                continue\n",
    "\n",
    "            score = 0.0\n",
    "            if config_item['type'] == 'direct':\n",
    "                score = float(value)\n",
    "            elif config_item['type'] == 'categorical':\n",
    "                score = float(config_item['mapping'].get(value, 0.0))\n",
    "            elif config_item['type'] in ['normalize', 'inverse_normalize']:\n",
    "                min_val, max_val = config_item['range']\n",
    "                # Avoid division by zero if range is a single point\n",
    "                if max_val == min_val:\n",
    "                    normalized = 0.0 if value == min_val else 1.0\n",
    "                else:\n",
    "                    # Clamp the value to be within the defined range for stable normalization\n",
    "                    clamped_value = max(min_val, min(value, max_val))\n",
    "                    normalized = (clamped_value - min_val) / (max_val - min_val)\n",
    "                \n",
    "                if config_item['type'] == 'inverse_normalize':\n",
    "                    score = 1.0 - normalized\n",
    "                else:\n",
    "                    score = normalized\n",
    "            scores.append(score)\n",
    "        \n",
    "        # The agent's final score is the highest score among its features\n",
    "        return max(scores)\n",
    "\n",
    "    def analyze(self, data_row: Dict) -> AgentResult:\n",
    "        \"\"\"Runs the full analysis process: rules, scoring, and optional LLM summary.\"\"\"\n",
    "        data_input = {k: data_row.get(k) for k in self.features if k in data_row}\n",
    "\n",
    "        # Step A: Apply deterministic rules\n",
    "        anomaly_detected, reasons = self._apply_rules(data_input)\n",
    "\n",
    "        # Step B: Calculate a deterministic score\n",
    "        score = self._calculate_score(data_input)\n",
    "        \n",
    "        # Step C: Get LLM summary ONLY if an anomaly is detected\n",
    "        summary = \"No anomalies detected.\"\n",
    "        if anomaly_detected:\n",
    "            chain = self.prompt_template | self.llm | self.parser\n",
    "            llm_output = chain.invoke({\"reasons_list\": \"\\n- \".join(reasons)})\n",
    "            summary = llm_output.get('summary', \"Summary could not be generated.\")\n",
    "\n",
    "        # Step D: Return the final, structured result\n",
    "        return AgentResult(\n",
    "            anomaly_detected=anomaly_detected,\n",
    "            score=score,\n",
    "            reasons=reasons,\n",
    "            summary=summary\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ca81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will handle all the supervisor's tasks.\n",
    "def run_supervisor(\n",
    "    agent_outputs: Dict[str, AgentResult],\n",
    "    supervisor_llm: ChatOpenAI,\n",
    "    config: Dict\n",
    ") -> SupervisorDecision:\n",
    "    \"\"\"\n",
    "    Aggregates worker agent results, calculates a global score, determines a risk level,\n",
    "    and generates final recommendations using the supervisor LLM.\n",
    "    \"\"\"\n",
    "    supervisor_config = config['supervisor']\n",
    "    \n",
    "    # 1. Calculate the weighted global score\n",
    "    global_score = 0.0\n",
    "    for agent_name, result in agent_outputs.items():\n",
    "        weight = supervisor_config['agent_weights'].get(agent_name, 0)\n",
    "        global_score += result.score * weight\n",
    "    \n",
    "    # 2. Determine the risk level based on thresholds in the config\n",
    "    thresholds = supervisor_config['risk_thresholds']\n",
    "    risk_level = \"LOW\"\n",
    "    if global_score >= thresholds['HIGH']:\n",
    "        risk_level = \"HIGH\"\n",
    "    elif global_score >= thresholds['MODERATE']:\n",
    "        risk_level = \"MODERATE\"\n",
    "\n",
    "    # 3. Prepare a summary for the LLM\n",
    "    report_summary = \"\"\n",
    "    for agent_name, result in agent_outputs.items():\n",
    "        if result.anomaly_detected:\n",
    "            report_summary += f\"Agent '{agent_name}' detected: {result.summary} (Score: {result.score:.2f})\\n\"\n",
    "    \n",
    "    if not report_summary:\n",
    "        report_summary = \"No anomalies were detected by any agent.\"\n",
    "\n",
    "    # 4. Generate final recommendations using the supervisor LLM\n",
    "    prompt = ChatPromptTemplate.from_template(supervisor_config['prompt'])\n",
    "    chain = prompt | supervisor_llm | StrOutputParser()\n",
    "    \n",
    "    llm_response = chain.invoke({\n",
    "        \"risk_level\": risk_level,\n",
    "        \"global_score\": global_score,\n",
    "        \"report_summary\": report_summary\n",
    "    })\n",
    "    \n",
    "    recommendations = [rec.strip() for rec in llm_response.strip().split('\\n') if rec.strip()]\n",
    "\n",
    "    # 5. Return the final decision object\n",
    "    return SupervisorDecision(\n",
    "        risk_level=risk_level,\n",
    "        global_score=global_score,\n",
    "        recommendations=recommendations\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42738b86",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edf4de16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 12:52:28,355 - INFO - Initialized 6 worker agents.\n"
     ]
    }
   ],
   "source": [
    "llm_worker = ChatOpenAI(model=config[\"worker_model\"])\n",
    "llm_supervisor = ChatOpenAI(model=config[\"supervisor_model\"])\n",
    "\n",
    "agents = {}\n",
    "for agent_name, agent_config in config.items():\n",
    "    if agent_name.startswith(\"agent_\"):\n",
    "        agents[agent_name] = WorkerAgent(\n",
    "            agent_name=agent_name,\n",
    "            config=agent_config,\n",
    "            llm=llm_worker\n",
    "        )\n",
    "logger.info(f\"Initialized {len(agents)} worker agents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64028bfc",
   "metadata": {},
   "source": [
    "# Workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7df4a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 12:56:01,923 - INFO - Use pytorch device_name: cuda\n",
      "2025-07-10 12:56:01,924 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "with open(r\"D:\\VeriFlow\\data\\ground_truth.json\", \"r\") as f:\n",
    "    ground_truth_data = json.load(f)\n",
    "    ground_truth_map = {item['row_index']: item for item in ground_truth_data}\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79256625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Main Workflow \n",
    "def process_row(\n",
    "    row_index: int,\n",
    "    data_row: Dict,\n",
    "    agents: Dict[str, WorkerAgent],\n",
    "    supervisor_llm: ChatOpenAI,\n",
    "    config: Dict\n",
    ") -> FinalReport:\n",
    "    \"\"\"\n",
    "    Orchestrates the processing of a single data row through all agents and the supervisor.\n",
    "    \"\"\"\n",
    "    # A. Run all worker agents serially\n",
    "    agent_outputs = {}\n",
    "    for agent_name, agent in agents.items():\n",
    "        logger.info(f\"Running agent: {agent_name} for row {row_index}...\")\n",
    "        agent_outputs[agent_name] = agent.analyze(data_row)\n",
    "\n",
    "    # B. Run the supervisor to aggregate results and make a final decision\n",
    "    logger.info(f\"Running supervisor for row {row_index}...\")\n",
    "    supervisor_decision = run_supervisor(agent_outputs, supervisor_llm, config)\n",
    "\n",
    "    # C. Create the final, structured report\n",
    "    description = supervisor_decision.recommendations[0] if supervisor_decision.recommendations else \"No significant issues to report.\"\n",
    "    \n",
    "    final_report = FinalReport(\n",
    "        row_index=row_index,\n",
    "        description=description,\n",
    "        agent_outputs=agent_outputs,\n",
    "        supervisor_decision=supervisor_decision\n",
    "    )\n",
    "    \n",
    "    return final_report\n",
    "\n",
    "# 2. Evaluation Function\n",
    "def evaluate_report(\n",
    "    final_report: FinalReport,\n",
    "    ground_truth: Dict\n",
    ") -> EvaluationMetrics:\n",
    "    \"\"\"\n",
    "    Compares a single FinalReport against its corresponding ground truth entry.\n",
    "    \"\"\"\n",
    "    # Supervisor Evaluation \n",
    "    supervisor_pred = final_report.supervisor_decision\n",
    "    supervisor_gt = ground_truth['expected_supervisor_decision']\n",
    "\n",
    "    # Accuracy of risk level \n",
    "    risk_level_accuracy = 1.0 if supervisor_pred.risk_level == supervisor_gt['expected_risk_level'] else 0.0\n",
    "    \n",
    "    # Error of the global score\n",
    "    global_score_error = abs(supervisor_pred.global_score - supervisor_gt['expected_global_score'])\n",
    "\n",
    "    # Semantic similarity of recommendations\n",
    "    pred_recs = \" \".join(supervisor_pred.recommendations)\n",
    "    gt_recs = \" \".join(supervisor_gt['expected_recommendations'])\n",
    "    pred_embedding = sentence_model.encode([pred_recs])\n",
    "    gt_embedding = sentence_model.encode([gt_recs])\n",
    "    recommendation_similarity = cosine_similarity(pred_embedding, gt_embedding)[0][0]\n",
    "\n",
    "    # Agent Evaluation\n",
    "    agent_accuracies = []\n",
    "    reason_similarities = []\n",
    "    agent_preds = final_report.agent_outputs\n",
    "    agent_gt = ground_truth['expected_agent_outputs']\n",
    "\n",
    "    for agent_name, agent_pred_result in agent_preds.items():\n",
    "        agent_gt_result = agent_gt.get(agent_name)\n",
    "        if agent_gt_result:\n",
    "            # Anomaly detection accuracy for each agent\n",
    "            is_correct = (agent_pred_result.anomaly_detected == agent_gt_result['anomaly_detected'])\n",
    "            agent_accuracies.append(1.0 if is_correct else 0.0)\n",
    "\n",
    "            # If there's an anomaly, compare the reasons/summary\n",
    "            if agent_pred_result.anomaly_detected and agent_gt_result['anomaly_detected']:\n",
    "                pred_reason = agent_pred_result.summary\n",
    "                gt_reason = \" \".join(agent_gt_result['expected_reasons'])\n",
    "                pred_emb = sentence_model.encode([pred_reason])\n",
    "                gt_emb = sentence_model.encode([gt_reason])\n",
    "                reason_similarities.append(cosine_similarity(pred_emb, gt_emb)[0][0])\n",
    "    \n",
    "    # Final Metrics \n",
    "    return EvaluationMetrics(\n",
    "        anomaly_detection_accuracy=np.mean(agent_accuracies) if agent_accuracies else 1.0,\n",
    "        risk_level_accuracy=risk_level_accuracy,\n",
    "        reason_similarity_score=np.mean(reason_similarities) if reason_similarities else 1.0,\n",
    "        recommendation_similarity_score=float(recommendation_similarity),\n",
    "        global_score_error=global_score_error\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2972ca16",
   "metadata": {},
   "source": [
    "# Execution Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf2a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 12:56:48,074 - INFO - Starting the main process...\n",
      "2025-07-10 12:56:49,971 - INFO - Initialized 6 worker agents.\n",
      "2025-07-10 12:56:49,972 - INFO - ----- Processing Row 1 -----\n",
      "2025-07-10 12:56:49,973 - INFO - Running agent: agent_1_geolocation for row 1...\n",
      "2025-07-10 12:56:51,754 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:56:51,769 - INFO - Running agent: agent_2_fuel for row 1...\n",
      "2025-07-10 12:56:51,770 - INFO - Running agent: agent_3_logistics for row 1...\n",
      "2025-07-10 12:56:51,770 - INFO - Running agent: agent_4_supplier for row 1...\n",
      "2025-07-10 12:56:53,427 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:56:53,431 - INFO - Running agent: agent_5_cargo for row 1...\n",
      "2025-07-10 12:56:56,833 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:56:56,842 - INFO - Running agent: agent_6_risk for row 1...\n",
      "2025-07-10 12:56:58,118 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:56:58,126 - INFO - Running supervisor for row 1...\n",
      "2025-07-10 12:57:01,282 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\Kevin Nathanael\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.29it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.69it/s]\n",
      "2025-07-10 12:57:01,936 - INFO - Finished processing and evaluating row 1. Risk Level: HIGH\n",
      "2025-07-10 12:57:01,936 - INFO - ----- Processing Row 2 -----\n",
      "2025-07-10 12:57:01,936 - INFO - Running agent: agent_1_geolocation for row 2...\n",
      "2025-07-10 12:57:02,855 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:57:02,859 - INFO - Running agent: agent_2_fuel for row 2...\n",
      "2025-07-10 12:57:02,859 - INFO - Running agent: agent_3_logistics for row 2...\n",
      "2025-07-10 12:57:04,531 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:57:04,535 - INFO - Running agent: agent_4_supplier for row 2...\n",
      "2025-07-10 12:57:05,516 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:57:05,519 - INFO - Running agent: agent_5_cargo for row 2...\n",
      "2025-07-10 12:57:06,735 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:57:06,739 - INFO - Running agent: agent_6_risk for row 2...\n",
      "2025-07-10 12:57:08,143 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:57:08,148 - INFO - Running supervisor for row 2...\n",
      "2025-07-10 12:57:09,969 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 123.50it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.02it/s]\n",
      "2025-07-10 12:57:10,197 - INFO - Finished processing and evaluating row 2. Risk Level: HIGH\n",
      "2025-07-10 12:57:10,198 - INFO - ----- Processing Row 3 -----\n",
      "2025-07-10 12:57:10,198 - INFO - Running agent: agent_1_geolocation for row 3...\n",
      "2025-07-10 12:57:10,199 - INFO - Running agent: agent_2_fuel for row 3...\n",
      "2025-07-10 12:57:10,199 - INFO - Running agent: agent_3_logistics for row 3...\n",
      "2025-07-10 12:57:11,813 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:57:11,818 - INFO - Running agent: agent_4_supplier for row 3...\n",
      "2025-07-10 12:57:11,818 - INFO - Running agent: agent_5_cargo for row 3...\n",
      "2025-07-10 12:57:11,819 - INFO - Running agent: agent_6_risk for row 3...\n",
      "2025-07-10 12:57:13,035 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:57:13,042 - INFO - Running supervisor for row 3...\n",
      "2025-07-10 12:57:14,207 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.43it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 84.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.07it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 76.93it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.34it/s]\n",
      "2025-07-10 12:57:14,310 - INFO - Finished processing and evaluating row 3. Risk Level: MODERATE\n",
      "2025-07-10 12:57:14,311 - INFO - ----- Processing Row 4 -----\n",
      "2025-07-10 12:57:14,312 - INFO - Running agent: agent_1_geolocation for row 4...\n",
      "2025-07-10 12:57:15,823 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:57:15,832 - INFO - Running agent: agent_2_fuel for row 4...\n",
      "2025-07-10 12:57:15,833 - INFO - Running agent: agent_3_logistics for row 4...\n",
      "2025-07-10 12:57:15,833 - INFO - Running agent: agent_4_supplier for row 4...\n",
      "2025-07-10 12:57:17,004 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:57:17,008 - INFO - Running agent: agent_5_cargo for row 4...\n",
      "2025-07-10 12:57:17,009 - INFO - Running agent: agent_6_risk for row 4...\n",
      "2025-07-10 12:57:18,518 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-10 12:57:18,526 - INFO - Running supervisor for row 4...\n",
      "2025-07-10 12:57:20,219 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.35it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.92it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.76it/s]\n",
      "2025-07-10 12:57:20,364 - INFO - Finished processing and evaluating row 4. Risk Level: HIGH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "           OVERALL SYSTEM EVALUATION SUMMARY\n",
      "============================================================\n",
      "Total Rows Processed: 4\n",
      "---\n",
      "Average Performance Metrics:\n",
      "  - Risk Level Accuracy:           75.00%\n",
      "  - Anomaly Detection Accuracy:    58.33%\n",
      "  - Recommendation Similarity:     0.570\n",
      "  - Agent Reason Similarity:       0.647\n",
      "  - Global Score Error (MAE):      0.106\n",
      "============================================================\n",
      "\n",
      "Sample Output for First Processed Row:\n",
      "\n",
      "{\n",
      "  \"row_index\": 1,\n",
      "  \"description\": \"1. IMMEDIATE: Avoid the critical route identified by agent_1_geolocation due to significant safety concerns.\",\n",
      "  \"agent_outputs\": {\n",
      "    \"agent_1_geolocation\": {\n",
      "      \"anomaly_detected\": true,\n",
      "      \"score\": 0.9611988304357689,\n",
      "      \"reasons\": [\n",
      "        \"Severe route risk level detected (9.61198830435769 on a 0-10 scale).\"\n",
      "      ],\n",
      "      \"summary\": \"A critical route risk has been identified, indicating significant safety concerns for movement in the area.\"\n",
      "    },\n",
      "    \"agent_2_fuel\": {\n",
      "      \"anomaly_detected\": false,\n",
      "      \"score\": 0.006767435376858918,\n",
      "      \"reasons\": [],\n",
      "      \"summary\": \"No anomalies detected.\"\n",
      "    },\n",
      "    \"agent_3_logistics\": {\n",
      "      \"anomaly_detected\": false,\n",
      "      \"score\": 0.701837332001688,\n",
      "      \"reasons\": [],\n",
      "      \"summary\": \"No anomalies detected.\"\n",
      "    },\n",
      "    \"agent_4_supplier\": {\n",
      "      \"anomaly_detected\": true,\n",
      "      \"score\": 0.8291546953486738,\n",
      "      \"reasons\": [\n",
      "        \"Supplier reliability score of 0.4632329921129754 is below the acceptable threshold.\",\n",
      "        \"Lead time of 12.608165734881434 days is excessive.\"\n",
      "      ],\n",
      "      \"summary\": \"The supplier exhibits poor performance with a reliability score of 0.46, below the acceptable threshold, and an excessive lead time of 12.61 days.\"\n",
      "    },\n",
      "    \"agent_5_cargo\": {\n",
      "      \"anomaly_detected\": true,\n",
      "      \"score\": 0.9081613825345626,\n",
      "      \"reasons\": [\n",
      "        \"IoT temperature of -9.753493205204748\\u00b0C is outside the safe range.\"\n",
      "      ],\n",
      "      \"summary\": \"The cargo is at risk of damage due to exposure to temperatures below the safe threshold of 0\\u00b0C.\"\n",
      "    },\n",
      "    \"agent_6_risk\": {\n",
      "      \"anomaly_detected\": true,\n",
      "      \"score\": 0.9807839828362244,\n",
      "      \"reasons\": [\n",
      "        \"Driver behavior score is critically low (0.2017253908480102).\",\n",
      "        \"High likelihood of external disruption (0.9807839828362244).\"\n",
      "      ],\n",
      "      \"summary\": \"The operational risk is high due to critically low driver behavior scores combined with a very high likelihood of external disruptions.\"\n",
      "    }\n",
      "  },\n",
      "  \"supervisor_decision\": {\n",
      "    \"risk_level\": \"HIGH\",\n",
      "    \"global_score\": 0.8039855168166343,\n",
      "    \"recommendations\": [\n",
      "      \"1. IMMEDIATE: Avoid the critical route identified by agent_1_geolocation due to significant safety concerns.\",\n",
      "      \"2. IMMEDIATE: Evaluate and potentially replace the supplier identified by agent_4_supplier with poor performance and excessive lead time.\",\n",
      "      \"3. IMMEDIATE: Take measures to protect the cargo from exposure to temperatures below 0\\u00b0C as identified by agent_5_cargo.\",\n",
      "      \"4. Evaluate and address the low driver behavior scores and high likelihood of external disruptions identified by agent_6_risk to mitigate operational risks.\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to initialize the system, process data, and evaluate results.\n",
    "    \"\"\"\n",
    "    # 1. SETUP\n",
    "    logger.info(\"Starting the main process...\")\n",
    "    \n",
    "    data_df = pd.read_csv(r\"D:\\VeriFlow\\data\\test_data.csv\")\n",
    "\n",
    "    # Initialize LLMs\n",
    "    llm_worker = ChatOpenAI(model=config['worker_model'], temperature=0.1)\n",
    "    llm_supervisor = ChatOpenAI(model=config['supervisor_model'], temperature=0.3)\n",
    "\n",
    "    # Initialize Worker Agents from config\n",
    "    agents = {}\n",
    "    for agent_name, agent_config in config.items():\n",
    "        if agent_name.startswith(\"agent_\"):\n",
    "            agents[agent_name] = WorkerAgent(\n",
    "                agent_name=agent_name,\n",
    "                config=agent_config,\n",
    "                llm=llm_worker\n",
    "            )\n",
    "    logger.info(f\"Initialized {len(agents)} worker agents.\")\n",
    "\n",
    "    # 2. PROCESSING & EVALUATION LOOP\n",
    "    all_reports = []\n",
    "    all_metrics = []\n",
    "\n",
    "    # Loop through each row of the dataframe\n",
    "    for index, row in data_df.head(5).iterrows():\n",
    "        # Only process rows that have a corresponding ground truth entry\n",
    "        if index not in ground_truth_map:\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"----- Processing Row {index} -----\")\n",
    "        \n",
    "        # A. Process the row to get the final report\n",
    "        final_report = process_row(index, row.to_dict(), agents, llm_supervisor, config)\n",
    "        all_reports.append(final_report)\n",
    "        \n",
    "        # B. Evaluate the report against the ground truth\n",
    "        ground_truth_entry = ground_truth_map[index]\n",
    "        metrics = evaluate_report(final_report, ground_truth_entry)\n",
    "        all_metrics.append(metrics)\n",
    "        \n",
    "        logger.info(f\"Finished processing and evaluating row {index}. Risk Level: {final_report.supervisor_decision.risk_level}\")\n",
    "\n",
    "    # 3. FINAL SUMMARY REPORT\n",
    "    if not all_metrics:\n",
    "        logger.warning(\"No data was processed, as no matching ground truth entries were found.\")\n",
    "        return\n",
    "        \n",
    "    # Create a DataFrame from our evaluation metrics for easy analysis\n",
    "    metrics_df = pd.DataFrame([asdict(m) for m in all_metrics])\n",
    "    average_metrics = metrics_df.mean()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"           OVERALL SYSTEM EVALUATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total Rows Processed: {len(all_metrics)}\")\n",
    "    print(\"---\")\n",
    "    print(\"Average Performance Metrics:\")\n",
    "    print(f\"  - Risk Level Accuracy:           {average_metrics['risk_level_accuracy']:.2%}\")\n",
    "    print(f\"  - Anomaly Detection Accuracy:    {average_metrics['anomaly_detection_accuracy']:.2%}\")\n",
    "    print(f\"  - Recommendation Similarity:     {average_metrics['recommendation_similarity_score']:.3f}\")\n",
    "    print(f\"  - Agent Reason Similarity:       {average_metrics['reason_similarity_score']:.3f}\")\n",
    "    print(f\"  - Global Score Error (MAE):      {average_metrics['global_score_error']:.3f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nSample Output for First Processed Row:\\n\")\n",
    "    print(json.dumps(asdict(all_reports[0]), indent=2))\n",
    "    print(\"=\"*60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
