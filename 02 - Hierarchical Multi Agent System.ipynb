{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b28381e2",
   "metadata": {},
   "source": [
    "# Libraries & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bac2db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kevin Nathanael\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, Tuple, List, Any, Optional\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b70451",
   "metadata": {},
   "source": [
    "# Data Classes Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d3ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AgentResult:\n",
    "    \"\"\"Holds the output from a single worker agent.\"\"\"\n",
    "    anomaly_detected: bool\n",
    "    score: float\n",
    "    reasons: List[str]  # Generated by the rules engine\n",
    "    summary: str        # Generated by the LLM\n",
    "\n",
    "@dataclass\n",
    "class SupervisorDecision:\n",
    "    \"\"\"Holds the final decision from the supervisor agent.\"\"\"\n",
    "    risk_level: str  # \"LOW\", \"MODERATE\", \"HIGH\"\n",
    "    global_score: float\n",
    "    recommendations: List[str]\n",
    "\n",
    "@dataclass\n",
    "class FinalReport:\n",
    "    \"\"\"Represents the entire structured output for a single row, matching the ground truth.\"\"\"\n",
    "    row_index: int\n",
    "    description: str\n",
    "    agent_outputs: Dict[str, AgentResult] # Using a Dict is key for easy lookup\n",
    "    supervisor_decision: SupervisorDecision\n",
    "\n",
    "@dataclass\n",
    "class EvaluationMetrics:\n",
    "    \"\"\"Holds all the metrics from comparing the FinalReport to the ground truth.\"\"\"\n",
    "    # Anomaly detection accuracy for all agents combined\n",
    "    anomaly_detection_accuracy: float\n",
    "    \n",
    "    # Accuracy of the supervisor's final risk level classification\n",
    "    risk_level_accuracy: float\n",
    "    \n",
    "    # Average semantic similarity of the agent's reasons\n",
    "    reason_similarity_score: float\n",
    "    \n",
    "    # Semantic similarity of the supervisor's recommendations\n",
    "    recommendation_similarity_score: float\n",
    "    \n",
    "    # The error margin of the calculated global score vs. expected\n",
    "    global_score_error: float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430dd567",
   "metadata": {},
   "source": [
    "# Agent & Supervisor Defininitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81590eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. It only defines what the LLM will return: a summary.\n",
    "class AgentLLMOutput(BaseModel):\n",
    "    \"\"\"Defines the expected JSON output structure from the worker agent's LLM call.\"\"\"\n",
    "    summary: str = Field(description=\"A brief, one-sentence summary of the detected anomalies.\")\n",
    "\n",
    "# 2. The new WorkerAgent class contains all the logic for rules, scoring, and summarization.\n",
    "class WorkerAgent:\n",
    "    \"\"\"A configurable worker agent that performs analysis based on rules and scoring logic.\"\"\"\n",
    "\n",
    "    def __init__(self, agent_name: str, config: Dict, llm: ChatOpenAI):\n",
    "        self.name = agent_name\n",
    "        self.features = config['features']\n",
    "        self.rules = config['rules']\n",
    "        self.scoring_config = config['scoring']\n",
    "        self.llm = llm\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(config['prompt'])\n",
    "        self.parser = JsonOutputParser(pydantic_object=AgentLLMOutput)\n",
    "\n",
    "    def _apply_rules(self, data_input: Dict) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"Applies the deterministic rules from the config to detect anomalies.\"\"\"\n",
    "        anomalies_found = False\n",
    "        reasons = []\n",
    "        for rule in self.rules:\n",
    "            feature = rule['feature']\n",
    "            value = data_input.get(feature)\n",
    "            if value is None:\n",
    "                continue\n",
    "\n",
    "            threshold = rule['threshold']\n",
    "            triggered = False\n",
    "            if rule['condition'] == 'greater_than' and value > threshold:\n",
    "                triggered = True\n",
    "            elif rule['condition'] == 'less_than' and value < threshold:\n",
    "                triggered = True\n",
    "            elif rule['condition'] == 'outside_range' and (value < threshold[0] or value > threshold[1]):\n",
    "                triggered = True\n",
    "            elif rule['condition'] == 'equals' and value == threshold:\n",
    "                triggered = True\n",
    "\n",
    "            if triggered:\n",
    "                anomalies_found = True\n",
    "                reasons.append(rule['reason'].format(value=value, threshold=threshold))\n",
    "        return anomalies_found, reasons\n",
    "\n",
    "    def _calculate_score(self, data_input: Dict) -> float:\n",
    "        \"\"\"Calculates a 0-1 risk score based on the scoring configuration.\"\"\"\n",
    "        scores = [0.0] # Start with 0.0 to handle cases with no matching features\n",
    "        for config_item in self.scoring_config:\n",
    "            feature = config_item['feature']\n",
    "            value = data_input.get(feature)\n",
    "            if value is None:\n",
    "                continue\n",
    "\n",
    "            score = 0.0\n",
    "            if config_item['type'] == 'direct':\n",
    "                score = float(value)\n",
    "            elif config_item['type'] == 'categorical':\n",
    "                score = float(config_item['mapping'].get(value, 0.0))\n",
    "            elif config_item['type'] in ['normalize', 'inverse_normalize']:\n",
    "                min_val, max_val = config_item['range']\n",
    "                # Avoid division by zero if range is a single point\n",
    "                if max_val == min_val:\n",
    "                    normalized = 0.0 if value == min_val else 1.0\n",
    "                else:\n",
    "                    # Clamp the value to be within the defined range for stable normalization\n",
    "                    clamped_value = max(min_val, min(value, max_val))\n",
    "                    normalized = (clamped_value - min_val) / (max_val - min_val)\n",
    "                \n",
    "                if config_item['type'] == 'inverse_normalize':\n",
    "                    score = 1.0 - normalized\n",
    "                else:\n",
    "                    score = normalized\n",
    "            scores.append(score)\n",
    "        \n",
    "        # The agent's final score is the highest score among its features\n",
    "        return max(scores)\n",
    "\n",
    "    def analyze(self, data_row: Dict) -> AgentResult:\n",
    "        \"\"\"Runs the full analysis process: rules, scoring, and optional LLM summary.\"\"\"\n",
    "        data_input = {k: data_row.get(k) for k in self.features if k in data_row}\n",
    "\n",
    "        # Step A: Apply deterministic rules\n",
    "        anomaly_detected, reasons = self._apply_rules(data_input)\n",
    "\n",
    "        # Step B: Calculate a deterministic score\n",
    "        score = self._calculate_score(data_input)\n",
    "        \n",
    "        # Step C: Get LLM summary ONLY if an anomaly is detected\n",
    "        summary = \"No anomalies detected.\"\n",
    "        if anomaly_detected:\n",
    "            chain = self.prompt_template | self.llm | self.parser\n",
    "            llm_output = chain.invoke({\"reasons_list\": \"\\n- \".join(reasons)})\n",
    "            summary = llm_output.get('summary', \"Summary could not be generated.\")\n",
    "\n",
    "        # Step D: Return the final, structured result\n",
    "        return AgentResult(\n",
    "            anomaly_detected=anomaly_detected,\n",
    "            score=score,\n",
    "            reasons=reasons,\n",
    "            summary=summary\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "032ca81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will handle all the supervisor's tasks.\n",
    "def run_supervisor(\n",
    "    agent_outputs: Dict[str, AgentResult],\n",
    "    supervisor_llm: ChatOpenAI,\n",
    "    config: Dict\n",
    ") -> SupervisorDecision:\n",
    "    \"\"\"\n",
    "    Aggregates worker agent results, calculates a global score, determines a risk level,\n",
    "    and generates final recommendations using the supervisor LLM.\n",
    "    \"\"\"\n",
    "    supervisor_config = config['supervisor']\n",
    "    \n",
    "    # 1. Calculate the weighted global score\n",
    "    global_score = 0.0\n",
    "    for agent_name, result in agent_outputs.items():\n",
    "        weight = supervisor_config['agent_weights'].get(agent_name, 0)\n",
    "        global_score += result.score * weight\n",
    "    \n",
    "    # 2. Determine the risk level based on thresholds in the config\n",
    "    thresholds = supervisor_config['risk_thresholds']\n",
    "    risk_level = \"LOW\"\n",
    "    if global_score >= thresholds['HIGH']:\n",
    "        risk_level = \"HIGH\"\n",
    "    elif global_score >= thresholds['MODERATE']:\n",
    "        risk_level = \"MODERATE\"\n",
    "\n",
    "    # 3. Prepare a summary for the LLM\n",
    "    report_summary = \"\"\n",
    "    for agent_name, result in agent_outputs.items():\n",
    "        if result.anomaly_detected:\n",
    "            report_summary += f\"Agent '{agent_name}' detected: {result.summary} (Score: {result.score:.2f})\\n\"\n",
    "    \n",
    "    if not report_summary:\n",
    "        report_summary = \"No anomalies were detected by any agent.\"\n",
    "\n",
    "    # 4. Generate final recommendations using the supervisor LLM\n",
    "    prompt = ChatPromptTemplate.from_template(supervisor_config['prompt'])\n",
    "    chain = prompt | supervisor_llm | StrOutputParser()\n",
    "    \n",
    "    llm_response = chain.invoke({\n",
    "        \"risk_level\": risk_level,\n",
    "        \"global_score\": global_score,\n",
    "        \"report_summary\": report_summary\n",
    "    })\n",
    "    \n",
    "    recommendations = [rec.strip() for rec in llm_response.strip().split('\\n') if rec.strip()]\n",
    "\n",
    "    # 5. Return the final decision object\n",
    "    return SupervisorDecision(\n",
    "        risk_level=risk_level,\n",
    "        global_score=global_score,\n",
    "        recommendations=recommendations\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42738b86",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edf4de16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 15:02:35,270 - INFO - Initialized 6 worker agents.\n"
     ]
    }
   ],
   "source": [
    "llm_worker = ChatOpenAI(model=config[\"worker_model\"])\n",
    "llm_supervisor = ChatOpenAI(model=config[\"supervisor_model\"])\n",
    "\n",
    "agents = {}\n",
    "for agent_name, agent_config in config.items():\n",
    "    if agent_name.startswith(\"agent_\"):\n",
    "        agents[agent_name] = WorkerAgent(\n",
    "            agent_name=agent_name,\n",
    "            config=agent_config,\n",
    "            llm=llm_worker\n",
    "        )\n",
    "logger.info(f\"Initialized {len(agents)} worker agents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64028bfc",
   "metadata": {},
   "source": [
    "# Workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7df4a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 15:02:35,326 - INFO - Use pytorch device_name: cuda\n",
      "2025-07-15 15:02:35,326 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "with open(r\"D:\\VeriFlow\\data\\ground_truth.json\", \"r\") as f:\n",
    "    ground_truth_data = json.load(f)\n",
    "    ground_truth_map = {item['row_index']: item for item in ground_truth_data}\n",
    "\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79256625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Main Workflow \n",
    "def process_row(\n",
    "    row_index: int,\n",
    "    data_row: Dict,\n",
    "    agents: Dict[str, WorkerAgent],\n",
    "    supervisor_llm: ChatOpenAI,\n",
    "    config: Dict\n",
    ") -> FinalReport:\n",
    "    \"\"\"\n",
    "    Orchestrates the processing of a single data row through all agents and the supervisor.\n",
    "    \"\"\"\n",
    "    # A. Run all worker agents serially\n",
    "    agent_outputs = {}\n",
    "    for agent_name, agent in agents.items():\n",
    "        logger.info(f\"Running agent: {agent_name} for row {row_index}...\")\n",
    "        agent_outputs[agent_name] = agent.analyze(data_row)\n",
    "\n",
    "    # B. Run the supervisor to aggregate results and make a final decision\n",
    "    logger.info(f\"Running supervisor for row {row_index}...\")\n",
    "    supervisor_decision = run_supervisor(agent_outputs, supervisor_llm, config)\n",
    "\n",
    "    # C. Create the final, structured report\n",
    "    description = supervisor_decision.recommendations[0] if supervisor_decision.recommendations else \"No significant issues to report.\"\n",
    "    \n",
    "    final_report = FinalReport(\n",
    "        row_index=row_index,\n",
    "        description=description,\n",
    "        agent_outputs=agent_outputs,\n",
    "        supervisor_decision=supervisor_decision\n",
    "    )\n",
    "    \n",
    "    return final_report\n",
    "\n",
    "# 2. Evaluation Function\n",
    "def evaluate_report(\n",
    "    final_report: FinalReport,\n",
    "    ground_truth: Dict\n",
    ") -> EvaluationMetrics:\n",
    "    \"\"\"\n",
    "    Compares a single FinalReport against its corresponding ground truth entry.\n",
    "    \"\"\"\n",
    "    # Supervisor Evaluation \n",
    "    supervisor_pred = final_report.supervisor_decision\n",
    "    supervisor_gt = ground_truth['supervisor_decision']\n",
    "\n",
    "    # Accuracy of risk level \n",
    "    risk_level_accuracy = 1.0 if supervisor_pred.risk_level == supervisor_gt['risk_level'] else 0.0\n",
    "    \n",
    "    # Error of the global score\n",
    "    global_score_error = abs(supervisor_pred.global_score - supervisor_gt['global_score'])\n",
    "\n",
    "    # Semantic similarity of recommendations\n",
    "    pred_recs = \" \".join(supervisor_pred.recommendations)\n",
    "    gt_recs = \" \".join(supervisor_gt['recommendations'])\n",
    "    pred_embedding = sentence_model.encode([pred_recs])\n",
    "    gt_embedding = sentence_model.encode([gt_recs])\n",
    "    recommendation_similarity = cosine_similarity(pred_embedding, gt_embedding)[0][0]\n",
    "\n",
    "    # Agent Evaluation\n",
    "    agent_accuracies = []\n",
    "    reason_similarities = []\n",
    "    agent_preds = final_report.agent_outputs\n",
    "    agent_gt = ground_truth['agent_outputs']\n",
    "\n",
    "    for agent_name, agent_pred_result in agent_preds.items():\n",
    "        agent_gt_result = agent_gt.get(agent_name)\n",
    "        if agent_gt_result:\n",
    "            # Anomaly detection accuracy for each agent\n",
    "            is_correct = (agent_pred_result.anomaly_detected == agent_gt_result['anomaly_detected'])\n",
    "            agent_accuracies.append(1.0 if is_correct else 0.0)\n",
    "\n",
    "            # If there's an anomaly, compare the reasons/summary\n",
    "            if agent_pred_result.anomaly_detected and agent_gt_result['anomaly_detected']:\n",
    "                pred_reason = agent_pred_result.summary\n",
    "                gt_reason = agent_gt_result['summary']\n",
    "                pred_emb = sentence_model.encode([pred_reason])\n",
    "                gt_emb = sentence_model.encode([gt_reason])\n",
    "                reason_similarities.append(cosine_similarity(pred_emb, gt_emb)[0][0])\n",
    "    \n",
    "    # Final Metrics \n",
    "    return EvaluationMetrics(\n",
    "        anomaly_detection_accuracy=np.mean(agent_accuracies) if agent_accuracies else 1.0,\n",
    "        risk_level_accuracy=risk_level_accuracy,\n",
    "        reason_similarity_score=np.mean(reason_similarities) if reason_similarities else 1.0,\n",
    "        recommendation_similarity_score=float(recommendation_similarity),\n",
    "        global_score_error=global_score_error\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2972ca16",
   "metadata": {},
   "source": [
    "# Execution Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25bf2a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 15:02:39,714 - INFO - Starting the main process...\n",
      "2025-07-15 15:02:41,723 - INFO - Initialized 6 worker agents.\n",
      "2025-07-15 15:02:41,724 - INFO - ----- Processing Row 1 -----\n",
      "2025-07-15 15:02:41,725 - INFO - Running agent: agent_1_geolocation for row 1...\n",
      "2025-07-15 15:02:43,292 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:02:43,308 - INFO - Running agent: agent_2_fuel for row 1...\n",
      "2025-07-15 15:02:43,308 - INFO - Running agent: agent_3_logistics for row 1...\n",
      "2025-07-15 15:02:43,309 - INFO - Running agent: agent_4_supplier for row 1...\n",
      "2025-07-15 15:02:44,938 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:02:44,941 - INFO - Running agent: agent_5_cargo for row 1...\n",
      "2025-07-15 15:02:46,241 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:02:46,244 - INFO - Running agent: agent_6_risk for row 1...\n",
      "2025-07-15 15:02:47,681 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:02:47,687 - INFO - Running supervisor for row 1...\n",
      "2025-07-15 15:02:49,439 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\Kevin Nathanael\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.10it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 83.33it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.66it/s]\n",
      "2025-07-15 15:02:49,787 - INFO - Finished processing and evaluating row 1. Risk Level: HIGH\n",
      "2025-07-15 15:02:49,788 - INFO - ----- Processing Row 2 -----\n",
      "2025-07-15 15:02:49,789 - INFO - Running agent: agent_1_geolocation for row 2...\n",
      "2025-07-15 15:02:51,099 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:02:51,104 - INFO - Running agent: agent_2_fuel for row 2...\n",
      "2025-07-15 15:02:51,104 - INFO - Running agent: agent_3_logistics for row 2...\n",
      "2025-07-15 15:02:52,258 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:02:52,261 - INFO - Running agent: agent_4_supplier for row 2...\n",
      "2025-07-15 15:02:53,540 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:02:53,544 - INFO - Running agent: agent_5_cargo for row 2...\n",
      "2025-07-15 15:02:55,044 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:02:55,048 - INFO - Running agent: agent_6_risk for row 2...\n",
      "2025-07-15 15:02:56,269 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:02:56,272 - INFO - Running supervisor for row 2...\n",
      "2025-07-15 15:02:57,951 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 162.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 93.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 109.61it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 117.68it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 133.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 120.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 199.99it/s]\n",
      "2025-07-15 15:02:58,437 - INFO - Finished processing and evaluating row 2. Risk Level: HIGH\n",
      "2025-07-15 15:02:58,438 - INFO - ----- Processing Row 3 -----\n",
      "2025-07-15 15:02:58,439 - INFO - Running agent: agent_1_geolocation for row 3...\n",
      "2025-07-15 15:02:58,440 - INFO - Running agent: agent_2_fuel for row 3...\n",
      "2025-07-15 15:02:58,440 - INFO - Running agent: agent_3_logistics for row 3...\n",
      "2025-07-15 15:02:59,585 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:02:59,588 - INFO - Running agent: agent_4_supplier for row 3...\n",
      "2025-07-15 15:02:59,589 - INFO - Running agent: agent_5_cargo for row 3...\n",
      "2025-07-15 15:02:59,590 - INFO - Running agent: agent_6_risk for row 3...\n",
      "2025-07-15 15:03:01,093 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:01,097 - INFO - Running supervisor for row 3...\n",
      "2025-07-15 15:03:01,967 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.42it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 52.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 71.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 17.69it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.67it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 66.66it/s]\n",
      "2025-07-15 15:03:02,132 - INFO - Finished processing and evaluating row 3. Risk Level: MODERATE\n",
      "2025-07-15 15:03:02,133 - INFO - ----- Processing Row 4 -----\n",
      "2025-07-15 15:03:02,134 - INFO - Running agent: agent_1_geolocation for row 4...\n",
      "2025-07-15 15:03:03,374 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:03,384 - INFO - Running agent: agent_2_fuel for row 4...\n",
      "2025-07-15 15:03:03,385 - INFO - Running agent: agent_3_logistics for row 4...\n",
      "2025-07-15 15:03:03,385 - INFO - Running agent: agent_4_supplier for row 4...\n",
      "2025-07-15 15:03:04,401 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:04,404 - INFO - Running agent: agent_5_cargo for row 4...\n",
      "2025-07-15 15:03:04,405 - INFO - Running agent: agent_6_risk for row 4...\n",
      "2025-07-15 15:03:05,389 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:05,393 - INFO - Running supervisor for row 4...\n",
      "2025-07-15 15:03:06,965 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 128.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 119.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 149.38it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 106.25it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 158.22it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 119.41it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 113.17it/s]\n",
      "2025-07-15 15:03:07,376 - INFO - Finished processing and evaluating row 4. Risk Level: HIGH\n",
      "2025-07-15 15:03:07,376 - INFO - ----- Processing Row 5 -----\n",
      "2025-07-15 15:03:07,377 - INFO - Running agent: agent_1_geolocation for row 5...\n",
      "2025-07-15 15:03:08,806 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:08,810 - INFO - Running agent: agent_2_fuel for row 5...\n",
      "2025-07-15 15:03:08,810 - INFO - Running agent: agent_3_logistics for row 5...\n",
      "2025-07-15 15:03:09,655 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:09,658 - INFO - Running agent: agent_4_supplier for row 5...\n",
      "2025-07-15 15:03:09,658 - INFO - Running agent: agent_5_cargo for row 5...\n",
      "2025-07-15 15:03:09,659 - INFO - Running agent: agent_6_risk for row 5...\n",
      "2025-07-15 15:03:10,800 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:10,804 - INFO - Running supervisor for row 5...\n",
      "2025-07-15 15:03:12,294 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 20.30it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.14it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.13it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.90it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.12it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 153.56it/s]\n",
      "2025-07-15 15:03:12,437 - INFO - Finished processing and evaluating row 5. Risk Level: HIGH\n",
      "2025-07-15 15:03:12,438 - INFO - ----- Processing Row 6 -----\n",
      "2025-07-15 15:03:12,439 - INFO - Running agent: agent_1_geolocation for row 6...\n",
      "2025-07-15 15:03:13,500 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:13,504 - INFO - Running agent: agent_2_fuel for row 6...\n",
      "2025-07-15 15:03:13,505 - INFO - Running agent: agent_3_logistics for row 6...\n",
      "2025-07-15 15:03:14,404 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:14,408 - INFO - Running agent: agent_4_supplier for row 6...\n",
      "2025-07-15 15:03:16,038 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:16,044 - INFO - Running agent: agent_5_cargo for row 6...\n",
      "2025-07-15 15:03:17,225 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:17,228 - INFO - Running agent: agent_6_risk for row 6...\n",
      "2025-07-15 15:03:18,422 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:18,426 - INFO - Running supervisor for row 6...\n",
      "2025-07-15 15:03:19,898 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 11.95it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 154.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.52it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 179.20it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.47it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.02it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.77it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.96it/s]\n",
      "2025-07-15 15:03:20,111 - INFO - Finished processing and evaluating row 6. Risk Level: HIGH\n",
      "2025-07-15 15:03:20,113 - INFO - ----- Processing Row 7 -----\n",
      "2025-07-15 15:03:20,113 - INFO - Running agent: agent_1_geolocation for row 7...\n",
      "2025-07-15 15:03:21,328 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:21,333 - INFO - Running agent: agent_2_fuel for row 7...\n",
      "2025-07-15 15:03:21,334 - INFO - Running agent: agent_3_logistics for row 7...\n",
      "2025-07-15 15:03:22,257 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:22,260 - INFO - Running agent: agent_4_supplier for row 7...\n",
      "2025-07-15 15:03:22,261 - INFO - Running agent: agent_5_cargo for row 7...\n",
      "2025-07-15 15:03:23,614 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:23,618 - INFO - Running agent: agent_6_risk for row 7...\n",
      "2025-07-15 15:03:24,686 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:24,690 - INFO - Running supervisor for row 7...\n",
      "2025-07-15 15:03:26,142 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 19.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 175.21it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 152.74it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 140.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 181.08it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.83it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 90.91it/s]\n",
      "2025-07-15 15:03:26,310 - INFO - Finished processing and evaluating row 7. Risk Level: HIGH\n",
      "2025-07-15 15:03:26,310 - INFO - ----- Processing Row 8 -----\n",
      "2025-07-15 15:03:26,311 - INFO - Running agent: agent_1_geolocation for row 8...\n",
      "2025-07-15 15:03:27,265 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:27,271 - INFO - Running agent: agent_2_fuel for row 8...\n",
      "2025-07-15 15:03:27,271 - INFO - Running agent: agent_3_logistics for row 8...\n",
      "2025-07-15 15:03:28,203 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:28,216 - INFO - Running agent: agent_4_supplier for row 8...\n",
      "2025-07-15 15:03:29,157 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:29,161 - INFO - Running agent: agent_5_cargo for row 8...\n",
      "2025-07-15 15:03:30,375 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:30,378 - INFO - Running agent: agent_6_risk for row 8...\n",
      "2025-07-15 15:03:30,379 - INFO - Running supervisor for row 8...\n",
      "2025-07-15 15:03:31,955 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.60it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.65it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 111.16it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.82it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.86it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.89it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.67it/s]\n",
      "2025-07-15 15:03:32,138 - INFO - Finished processing and evaluating row 8. Risk Level: MODERATE\n",
      "2025-07-15 15:03:32,139 - INFO - ----- Processing Row 9 -----\n",
      "2025-07-15 15:03:32,140 - INFO - Running agent: agent_1_geolocation for row 9...\n",
      "2025-07-15 15:03:32,140 - INFO - Running agent: agent_2_fuel for row 9...\n",
      "2025-07-15 15:03:32,141 - INFO - Running agent: agent_3_logistics for row 9...\n",
      "2025-07-15 15:03:33,398 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:33,404 - INFO - Running agent: agent_4_supplier for row 9...\n",
      "2025-07-15 15:03:34,453 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:34,456 - INFO - Running agent: agent_5_cargo for row 9...\n",
      "2025-07-15 15:03:35,840 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:35,861 - INFO - Running agent: agent_6_risk for row 9...\n",
      "2025-07-15 15:03:36,941 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:36,945 - INFO - Running supervisor for row 9...\n",
      "2025-07-15 15:03:37,963 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  9.37it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.80it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.99it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 129.91it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.70it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.98it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.01it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.65it/s]\n",
      "2025-07-15 15:03:38,184 - INFO - Finished processing and evaluating row 9. Risk Level: HIGH\n",
      "2025-07-15 15:03:38,184 - INFO - ----- Processing Row 10 -----\n",
      "2025-07-15 15:03:38,185 - INFO - Running agent: agent_1_geolocation for row 10...\n",
      "2025-07-15 15:03:39,319 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:39,324 - INFO - Running agent: agent_2_fuel for row 10...\n",
      "2025-07-15 15:03:39,324 - INFO - Running agent: agent_3_logistics for row 10...\n",
      "2025-07-15 15:03:39,325 - INFO - Running agent: agent_4_supplier for row 10...\n",
      "2025-07-15 15:03:39,325 - INFO - Running agent: agent_5_cargo for row 10...\n",
      "2025-07-15 15:03:40,422 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:40,426 - INFO - Running agent: agent_6_risk for row 10...\n",
      "2025-07-15 15:03:41,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-15 15:03:41,460 - INFO - Running supervisor for row 10...\n",
      "2025-07-15 15:03:42,922 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.58it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 62.44it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 69.05it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 125.03it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 166.63it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 142.14it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 146.16it/s]\n",
      "2025-07-15 15:03:43,306 - INFO - Finished processing and evaluating row 10. Risk Level: HIGH\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "           OVERALL SYSTEM EVALUATION SUMMARY\n",
      "============================================================\n",
      "Total Rows Processed: 10\n",
      "---\n",
      "Average Performance Metrics:\n",
      "  - Risk Level Accuracy:           100.00%\n",
      "  - Anomaly Detection Accuracy:    100.00%\n",
      "  - Recommendation Similarity:     0.750\n",
      "  - Agent Reason Similarity:       0.802\n",
      "  - Global Score Error (MAE):      0.000\n",
      "============================================================\n",
      "\n",
      "Sample Output for First Processed Row:\n",
      "\n",
      "{\n",
      "  \"row_index\": 1,\n",
      "  \"description\": \"- IMMEDIATE: Avoid travel through the area with severe route risk (agent_1_geolocation).\",\n",
      "  \"agent_outputs\": {\n",
      "    \"agent_1_geolocation\": {\n",
      "      \"anomaly_detected\": true,\n",
      "      \"score\": 0.9611988304357689,\n",
      "      \"reasons\": [\n",
      "        \"Severe route risk level detected (9.61198830435769 on a 0-10 scale).\"\n",
      "      ],\n",
      "      \"summary\": \"A severe route risk has been identified, indicating significant safety concerns for travel in the area.\"\n",
      "    },\n",
      "    \"agent_2_fuel\": {\n",
      "      \"anomaly_detected\": false,\n",
      "      \"score\": 0.006767435376858918,\n",
      "      \"reasons\": [],\n",
      "      \"summary\": \"No anomalies detected.\"\n",
      "    },\n",
      "    \"agent_3_logistics\": {\n",
      "      \"anomaly_detected\": false,\n",
      "      \"score\": 0.701837332001688,\n",
      "      \"reasons\": [],\n",
      "      \"summary\": \"No anomalies detected.\"\n",
      "    },\n",
      "    \"agent_4_supplier\": {\n",
      "      \"anomaly_detected\": true,\n",
      "      \"score\": 0.8291546953486738,\n",
      "      \"reasons\": [\n",
      "        \"Supplier reliability score of 0.4632329921129754 is below the acceptable threshold.\",\n",
      "        \"Lead time of 12.608165734881434 days is excessive.\"\n",
      "      ],\n",
      "      \"summary\": \"The supplier exhibits poor performance with a reliability score of 0.46, below the acceptable threshold, and an excessive lead time of 12.61 days.\"\n",
      "    },\n",
      "    \"agent_5_cargo\": {\n",
      "      \"anomaly_detected\": true,\n",
      "      \"score\": 0.9081613825345626,\n",
      "      \"reasons\": [\n",
      "        \"IoT temperature of -9.753493205204748\\u00b0C is outside the safe range.\"\n",
      "      ],\n",
      "      \"summary\": \"The cargo is at risk of damage due to exposure to temperatures below the safe threshold of 0\\u00b0C.\"\n",
      "    },\n",
      "    \"agent_6_risk\": {\n",
      "      \"anomaly_detected\": true,\n",
      "      \"score\": 0.9807839828362244,\n",
      "      \"reasons\": [\n",
      "        \"Driver behavior score is critically low (0.2017253908480102).\",\n",
      "        \"High likelihood of external disruption (0.9807839828362244).\"\n",
      "      ],\n",
      "      \"summary\": \"The operational risk is high due to critically low driver behavior scores combined with a very high likelihood of external disruptions.\"\n",
      "    }\n",
      "  },\n",
      "  \"supervisor_decision\": {\n",
      "    \"risk_level\": \"HIGH\",\n",
      "    \"global_score\": 0.8039855168166343,\n",
      "    \"recommendations\": [\n",
      "      \"- IMMEDIATE: Avoid travel through the area with severe route risk (agent_1_geolocation).\",\n",
      "      \"- IMMEDIATE: Evaluate and potentially replace the poor-performing supplier with a reliability score of 0.46 and excessive lead time of 12.61 days (agent_4_supplier).\",\n",
      "      \"- Ensure that the cargo is protected from temperatures below the safe threshold of 0\\u00b0C (agent_5_cargo).\",\n",
      "      \"- Address the critically low driver behavior scores and high likelihood of external disruptions to mitigate operational risk (agent_6_risk).\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to initialize the system, process data, and evaluate results.\n",
    "    \"\"\"\n",
    "    # 1. SETUP\n",
    "    logger.info(\"Starting the main process...\")\n",
    "    \n",
    "    data_df = pd.read_csv(r\"D:\\VeriFlow\\data\\test_data.csv\")\n",
    "\n",
    "    # Initialize LLMs\n",
    "    llm_worker = ChatOpenAI(model=config['worker_model'], temperature=0.1)\n",
    "    llm_supervisor = ChatOpenAI(model=config['supervisor_model'], temperature=0.3)\n",
    "\n",
    "    # Initialize Worker Agents from config\n",
    "    agents = {}\n",
    "    for agent_name, agent_config in config.items():\n",
    "        if agent_name.startswith(\"agent_\"):\n",
    "            agents[agent_name] = WorkerAgent(\n",
    "                agent_name=agent_name,\n",
    "                config=agent_config,\n",
    "                llm=llm_worker\n",
    "            )\n",
    "    logger.info(f\"Initialized {len(agents)} worker agents.\")\n",
    "\n",
    "    # 2. PROCESSING & EVALUATION LOOP\n",
    "    all_reports = []\n",
    "    all_metrics = []\n",
    "\n",
    "    # Loop through each row of the dataframe\n",
    "    for index, row in data_df.head(11).iterrows():\n",
    "        # Only process rows that have a corresponding ground truth entry\n",
    "        if index not in ground_truth_map:\n",
    "            continue\n",
    "\n",
    "        logger.info(f\"----- Processing Row {index} -----\")\n",
    "        \n",
    "        # A. Process the row to get the final report\n",
    "        final_report = process_row(index, row.to_dict(), agents, llm_supervisor, config)\n",
    "        all_reports.append(final_report)\n",
    "        \n",
    "        # B. Evaluate the report against the ground truth\n",
    "        ground_truth_entry = ground_truth_map[index]\n",
    "        metrics = evaluate_report(final_report, ground_truth_entry)\n",
    "        all_metrics.append(metrics)\n",
    "        \n",
    "        logger.info(f\"Finished processing and evaluating row {index}. Risk Level: {final_report.supervisor_decision.risk_level}\")\n",
    "\n",
    "    # 3. FINAL SUMMARY REPORT\n",
    "    if not all_metrics:\n",
    "        logger.warning(\"No data was processed, as no matching ground truth entries were found.\")\n",
    "        return\n",
    "        \n",
    "    # Create a DataFrame from our evaluation metrics for easy analysis\n",
    "    metrics_df = pd.DataFrame([asdict(m) for m in all_metrics])\n",
    "    average_metrics = metrics_df.mean()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"           OVERALL SYSTEM EVALUATION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total Rows Processed: {len(all_metrics)}\")\n",
    "    print(\"---\")\n",
    "    print(\"Average Performance Metrics:\")\n",
    "    print(f\"  - Risk Level Accuracy:           {average_metrics['risk_level_accuracy']:.2%}\")\n",
    "    print(f\"  - Anomaly Detection Accuracy:    {average_metrics['anomaly_detection_accuracy']:.2%}\")\n",
    "    print(f\"  - Recommendation Similarity:     {average_metrics['recommendation_similarity_score']:.3f}\")\n",
    "    print(f\"  - Agent Reason Similarity:       {average_metrics['reason_similarity_score']:.3f}\")\n",
    "    print(f\"  - Global Score Error (MAE):      {average_metrics['global_score_error']:.3f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nSample Output for First Processed Row:\\n\")\n",
    "    print(json.dumps(asdict(all_reports[0]), indent=2))\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return all_reports\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_generated_reports = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec898c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <h2 style=\"text-align: center; color: #FFFFFF;\">Comparison for Row Index: 10</h2>\n",
       "    <div style=\"display: flex; flex-direction: row; justify-content: space-between; width: 100%;\">\n",
       "        <div style=\"width: 49%; border: 1px solid #ccc; border-radius: 8px; padding: 10px; \n",
       "                    box-sizing: border-box; background-color: #000000; color: #ffa500;\">\n",
       "            <h3 style=\"text-align: center; color: #FFFFFF;\">Generated Result</h3>\n",
       "            <pre style=\"white-space: pre-wrap; word-wrap: break-word; font-family: monospace; font-size: 13px;\">{\n",
       "  &quot;row_index&quot;: 10,\n",
       "  &quot;description&quot;: &quot;IMMEDIATE: Address the extremely high probability of delay in geolocation and movement data.&quot;,\n",
       "  &quot;agent_outputs&quot;: {\n",
       "    &quot;agent_1_geolocation&quot;: {\n",
       "      &quot;anomaly_detected&quot;: true,\n",
       "      &quot;score&quot;: 0.999999120978744,\n",
       "      &quot;reasons&quot;: [\n",
       "        &quot;High probability of delay (0.999999120978744).&quot;\n",
       "      ],\n",
       "      &quot;summary&quot;: &quot;There is an extremely high probability of delay detected in the geolocation and movement data.&quot;\n",
       "    },\n",
       "    &quot;agent_2_fuel&quot;: {\n",
       "      &quot;anomaly_detected&quot;: false,\n",
       "      &quot;score&quot;: 0.1067962032471991,\n",
       "      &quot;reasons&quot;: [],\n",
       "      &quot;summary&quot;: &quot;No anomalies detected.&quot;\n",
       "    },\n",
       "    &quot;agent_3_logistics&quot;: {\n",
       "      &quot;anomaly_detected&quot;: false,\n",
       "      &quot;score&quot;: 0.8538709127867701,\n",
       "      &quot;reasons&quot;: [],\n",
       "      &quot;summary&quot;: &quot;No anomalies detected.&quot;\n",
       "    },\n",
       "    &quot;agent_4_supplier&quot;: {\n",
       "      &quot;anomaly_detected&quot;: false,\n",
       "      &quot;score&quot;: 0.47303776891123245,\n",
       "      &quot;reasons&quot;: [],\n",
       "      &quot;summary&quot;: &quot;No anomalies detected.&quot;\n",
       "    },\n",
       "    &quot;agent_5_cargo&quot;: {\n",
       "      &quot;anomaly_detected&quot;: true,\n",
       "      &quot;score&quot;: 0.9974126720069126,\n",
       "      &quot;reasons&quot;: [\n",
       "        &quot;IoT temperature of 26.21889301309279\\u00b0C is outside the safe range.&quot;\n",
       "      ],\n",
       "      &quot;summary&quot;: &quot;The cargo is at risk due to elevated temperature of 26.22\\u00b0C, which exceeds the safe range, potentially compromising its integrity.&quot;\n",
       "    },\n",
       "    &quot;agent_6_risk&quot;: {\n",
       "      &quot;anomaly_detected&quot;: true,\n",
       "      &quot;score&quot;: 0.9737112925483569,\n",
       "      &quot;reasons&quot;: [\n",
       "        &quot;Driver behavior score is critically low (0.0262887074516431).&quot;,\n",
       "        &quot;High driver fatigue detected (score: 0.1888937993825616).&quot;,\n",
       "        &quot;High likelihood of external disruption (0.9629697600223964).&quot;\n",
       "      ],\n",
       "      &quot;summary&quot;: &quot;The operational risk is critically high due to extremely low driver behavior scores, significant driver fatigue, and a very high likelihood of external disruption.&quot;\n",
       "    }\n",
       "  },\n",
       "  &quot;supervisor_decision&quot;: {\n",
       "    &quot;risk_level&quot;: &quot;HIGH&quot;,\n",
       "    &quot;global_score&quot;: 0.8027554707132952,\n",
       "    &quot;recommendations&quot;: [\n",
       "      &quot;IMMEDIATE: Address the extremely high probability of delay in geolocation and movement data.&quot;,\n",
       "      &quot;IMMEDIATE: Take action to mitigate the risk to the cargo due to elevated temperature exceeding the safe range.&quot;,\n",
       "      &quot;IMMEDIATE: Implement measures to improve driver behavior scores, address driver fatigue, and prepare for potential external disruptions.&quot;\n",
       "    ]\n",
       "  }\n",
       "}</pre>\n",
       "        </div>\n",
       "        <div style=\"width: 49%; border: 1px solid #ccc; border-radius: 8px; padding: 10px;\n",
       "                    box-sizing: border-box; background-color: #000000; color: #ffa500;\">\n",
       "            <h3 style=\"text-align: center; color: #FFFFFF;\">Ground Truth</h3>\n",
       "            <pre style=\"white-space: pre-wrap; word-wrap: break-word; font-family: monospace; font-size: 13px;\">{\n",
       "  &quot;row_index&quot;: 10,\n",
       "  &quot;description&quot;: &quot;The shipment is at high risk, with a near-certainty of delay, a cargo temperature breach, and a critical driver status including poor behavior and high fatigue.&quot;,\n",
       "  &quot;agent_outputs&quot;: {\n",
       "    &quot;agent_1_geolocation&quot;: {\n",
       "      &quot;anomaly_detected&quot;: true,\n",
       "      &quot;score&quot;: 1.0,\n",
       "      &quot;reasons&quot;: [\n",
       "        &quot;High probability of delay (0.999999120978744).&quot;\n",
       "      ],\n",
       "      &quot;summary&quot;: &quot;A near-certain probability of delay has been detected for the shipment.&quot;\n",
       "    },\n",
       "    &quot;agent_2_fuel&quot;: {\n",
       "      &quot;anomaly_detected&quot;: false,\n",
       "      &quot;score&quot;: 0.107,\n",
       "      &quot;reasons&quot;: [],\n",
       "      &quot;summary&quot;: &quot;No anomalies detected.&quot;\n",
       "    },\n",
       "    &quot;agent_3_logistics&quot;: {\n",
       "      &quot;anomaly_detected&quot;: false,\n",
       "      &quot;score&quot;: 0.854,\n",
       "      &quot;reasons&quot;: [],\n",
       "      &quot;summary&quot;: &quot;No anomalies detected.&quot;\n",
       "    },\n",
       "    &quot;agent_4_supplier&quot;: {\n",
       "      &quot;anomaly_detected&quot;: false,\n",
       "      &quot;score&quot;: 0.473,\n",
       "      &quot;reasons&quot;: [],\n",
       "      &quot;summary&quot;: &quot;No anomalies detected.&quot;\n",
       "    },\n",
       "    &quot;agent_5_cargo&quot;: {\n",
       "      &quot;anomaly_detected&quot;: true,\n",
       "      &quot;score&quot;: 0.997,\n",
       "      &quot;reasons&quot;: [\n",
       "        &quot;IoT temperature of 26.21889301309279\\u00b0C is outside the safe range.&quot;\n",
       "      ],\n",
       "      &quot;summary&quot;: &quot;Cargo integrity is at risk as the temperature has exceeded the safe operational range.&quot;\n",
       "    },\n",
       "    &quot;agent_6_risk&quot;: {\n",
       "      &quot;anomaly_detected&quot;: true,\n",
       "      &quot;score&quot;: 0.974,\n",
       "      &quot;reasons&quot;: [\n",
       "        &quot;Driver behavior score is critically low (0.0262887074516431).&quot;,\n",
       "        &quot;High driver fatigue detected (score: 0.1888937993825616).&quot;,\n",
       "        &quot;High likelihood of external disruption (0.9629697600223964).&quot;\n",
       "      ],\n",
       "      &quot;summary&quot;: &quot;Critical operational risk exists due to poor driver metrics and a high likelihood of external disruption.&quot;\n",
       "    }\n",
       "  },\n",
       "  &quot;supervisor_decision&quot;: {\n",
       "    &quot;risk_level&quot;: &quot;HIGH&quot;,\n",
       "    &quot;global_score&quot;: 0.803,\n",
       "    &quot;recommendations&quot;: [\n",
       "      &quot;IMMEDIATE: Contact driver to address critical behavior and fatigue scores; halt shipment if necessary for safety.&quot;,\n",
       "      &quot;Notify receiving party of the high probability of delay and investigate the cargo temperature breach upon arrival.&quot;,\n",
       "      &quot;Update contingency plans to account for the high likelihood of external disruption.&quot;\n",
       "    ]\n",
       "  }\n",
       "}</pre>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import html\n",
    "\n",
    "def display_comparison(row_index: int):\n",
    "    \"\"\"\n",
    "    Displays a side-by-side comparison of the generated report and the ground truth\n",
    "    for a specific row index.\n",
    "    \"\"\"\n",
    "    # Find the generated report for the given index\n",
    "    generated_report = next((r for r in all_generated_reports if r.row_index == row_index), None)\n",
    "    \n",
    "    # Find the corresponding ground truth\n",
    "    ground_truth_entry = ground_truth_map.get(row_index)\n",
    "\n",
    "    if not generated_report:\n",
    "        print(f\"Error: No generated report found for row_index {row_index}. It might not have been processed.\")\n",
    "        return\n",
    "        \n",
    "    if not ground_truth_entry:\n",
    "        print(f\"Error: No ground truth entry found for row_index {row_index}.\")\n",
    "        return\n",
    "\n",
    "    # Convert both to formatted JSON strings\n",
    "    generated_json_str = json.dumps(asdict(generated_report), indent=2)\n",
    "    ground_truth_json_str = json.dumps(ground_truth_entry, indent=2)\n",
    "\n",
    "    # Escape special characters for safe HTML display\n",
    "    escaped_generated = html.escape(generated_json_str)\n",
    "    escaped_ground_truth = html.escape(ground_truth_json_str)\n",
    "\n",
    "    # Create the HTML for the two-column view\n",
    "    side_by_side_html = f\"\"\"\n",
    "    <h2 style=\"text-align: center; color: #FFFFFF;\">Comparison for Row Index: {row_index}</h2>\n",
    "    <div style=\"display: flex; flex-direction: row; justify-content: space-between; width: 100%;\">\n",
    "        <div style=\"width: 49%; border: 1px solid #ccc; border-radius: 8px; padding: 10px; \n",
    "                    box-sizing: border-box; background-color: #000000; color: #ffa500;\">\n",
    "            <h3 style=\"text-align: center; color: #FFFFFF;\">Generated Result</h3>\n",
    "            <pre style=\"white-space: pre-wrap; word-wrap: break-word; font-family: monospace; font-size: 13px;\">{escaped_generated}</pre>\n",
    "        </div>\n",
    "        <div style=\"width: 49%; border: 1px solid #ccc; border-radius: 8px; padding: 10px;\n",
    "                    box-sizing: border-box; background-color: #000000; color: #ffa500;\">\n",
    "            <h3 style=\"text-align: center; color: #FFFFFF;\">Ground Truth</h3>\n",
    "            <pre style=\"white-space: pre-wrap; word-wrap: break-word; font-family: monospace; font-size: 13px;\">{escaped_ground_truth}</pre>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    # Display the result\n",
    "    display(HTML(side_by_side_html))\n",
    "\n",
    "display_comparison(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd60315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
